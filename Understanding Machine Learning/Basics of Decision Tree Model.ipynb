{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌳 Basics of Decision Tree Model\n",
    "\n",
    "Welcome to this detailed guide on Decision Tree models! Let's explore the components, working, and applications of this intuitive machine learning algorithm. 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition\n",
    "\n",
    "A Decision Tree is a supervised learning algorithm used for classification and regression tasks. It splits the data into subsets based on feature values, forming a tree-like structure. 🌲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Components of a Decision Tree\n",
    "\n",
    "- **Root Node**: The top node representing the entire dataset. 🌳\n",
    "- **Splitting**: The process of dividing a node into two or more sub-nodes. ✂️\n",
    "- **Decision Node**: A node that splits into further sub-nodes. 🔀\n",
    "- **Leaf/Terminal Node**: A node that does not split further and represents a class label or output. 🍃\n",
    "- **Pruning**: The process of removing sub-nodes to prevent overfitting. ✂️\n",
    "- **Branch/Sub-Tree**: A subsection of the entire tree. 🌿\n",
    "- **Parent and Child Node**: Nodes connected by a branch, where the parent splits into child nodes. 👪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How Decision Trees Work\n",
    "\n",
    "- Start at the root node.\n",
    "- Split the data based on the best attribute using a selection measure.\n",
    "- Repeat splitting recursively for each child node.\n",
    "- Stop when nodes are pure or meet stopping criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Steps to Build a Decision Tree\n",
    "\n",
    "1. Select the best attribute using attribute selection measures. 🔍\n",
    "2. Split the dataset into subsets based on the attribute. ✂️\n",
    "3. Repeat recursively for each subset. 🔄\n",
    "4. Stop when all data in a node belongs to the same class or no further splitting is possible. 🛑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attribute Selection Measures\n",
    "\n",
    "- **Information Gain**: Measures the reduction in entropy after a dataset is split on an attribute. 📉\n",
    "- **Gini Index**: Measures the impurity of a dataset; lower values indicate better splits. ⚖️\n",
    "- **Chi-Square**: Statistical test to measure the independence of attributes. 📊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example: Building a Decision Tree\n",
    "\n",
    "Consider a dataset of weather conditions and whether to play tennis. The decision tree splits based on attributes like outlook, humidity, and wind to predict the outcome. 🌞🌧️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Python Code Example\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create Decision Tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Applications of Decision Tree Models\n",
    "\n",
    "- Credit Scoring 💳\n",
    "- Medical Diagnosis 🏥\n",
    "- Customer Segmentation 👥\n",
    "- Risk Management ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advantages\n",
    "\n",
    "- Easy to understand and interpret. 🧠\n",
    "- Requires little data preprocessing. 🧹\n",
    "- Can handle both numerical and categorical data. 🔢🔤\n",
    "- Non-parametric and flexible. 🔄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Disadvantages\n",
    "\n",
    "- Prone to overfitting. ⚠️\n",
    "- Can be unstable with small variations in data. 🔄\n",
    "- Biased towards attributes with more levels. ⚖️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "Decision Trees are powerful and interpretable models widely used in machine learning. Understanding their components and working is essential for effective application. 🌟"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
