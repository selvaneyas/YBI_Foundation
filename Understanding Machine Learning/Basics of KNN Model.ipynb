{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š Basics of KNN Model\n",
    "\n",
    "Welcome to this interactive guide on the K-Nearest Neighbors (KNN) algorithm! Let's explore how KNN works, its applications, and implementation in Python. ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. KNN Model\n",
    "\n",
    "KNN is a simple, instance-based learning algorithm used for classification and regression tasks. It predicts the output based on the 'k' closest training examples in the feature space. ğŸ§©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNN for Classification\n",
    "\n",
    "In classification, KNN assigns the class most common among its k nearest neighbors. ğŸ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KNN for Regression\n",
    "\n",
    "In regression, KNN predicts the output as the average of the values of its k nearest neighbors. ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How KNN Works\n",
    "\n",
    "- Calculate the distance between the query instance and all training samples. ğŸ“\n",
    "- Select the k nearest neighbors based on distance. ğŸ§­\n",
    "- Aggregate the outputs of neighbors (majority vote for classification, average for regression). ğŸ—³ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Steps to Implement k-NN\n",
    "\n",
    "1. Choose the number of neighbors (k). ğŸ”¢\n",
    "2. Calculate distance metric (e.g., Euclidean distance). ğŸ“\n",
    "3. Find k nearest neighbors. ğŸ§­\n",
    "4. Aggregate neighbor outputs. ğŸ—³ï¸\n",
    "5. Assign prediction. ğŸ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Choosing a Good Value for k\n",
    "\n",
    "- Small k can be noisy and sensitive to outliers. âš ï¸\n",
    "- Large k makes it computationally expensive and may smooth out boundaries. ğŸ¢\n",
    "- Use cross-validation to find optimal k. ğŸ”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advantages of k-NN\n",
    "\n",
    "- Simple to understand and implement. ğŸ§ \n",
    "- No training phase (lazy learning). ğŸ›‹ï¸\n",
    "- Works well with multi-modal classes. ğŸ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Disadvantages of k-NN\n",
    "\n",
    "- Computationally expensive during prediction. â³\n",
    "- Sensitive to irrelevant features and the scale of data. âš–ï¸\n",
    "- Requires large memory to store training data. ğŸ’¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Applications of k-NN\n",
    "\n",
    "- Pattern recognition ğŸ–¼ï¸\n",
    "- Recommendation systems ğŸ“Š\n",
    "- Image classification ğŸ–¼ï¸\n",
    "- Medical diagnosis ğŸ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Practical Tips\n",
    "\n",
    "- Normalize or standardize data before applying k-NN. âš–ï¸\n",
    "- Use efficient data structures like KD-trees for faster neighbor search. ğŸŒ²\n",
    "- Experiment with different distance metrics. ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Source Code Using Python\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
